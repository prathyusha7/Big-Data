import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.spark.streaming._
import org.apache.spark.streaming.StreamingContext._

val consumerKey = "xpdMt9BXC9xEn4YPNoUqIF007"
val consumerSecret = "kAksUjxqhsfgEZy90q05TErQWdg9Bol5S7W7XB4VPeHqfeKf1L"
val accessToken = "504320236-Z1mmqywh1t9qMVo1IB7yueo6aVNg9511odpGypBW"
val accessTokenSecret = "OCzVnF352xK3sntJXsZU4gMVXGCOUHE9i3Ehu1OEGo8N7"
val path = "/tmp/mounica"
val savingInterval = 5000 // create a new file every 2 seconds
val filters = Array("Dallas", "Restaurant")

import java.io.{BufferedReader, File, FileNotFoundException, InputStream, InputStreamReader}
import java.net.URLEncoder
import java.nio.charset.StandardCharsets
import java.util.Base64
import javax.crypto.Mac
import javax.crypto.spec.SecretKeySpec

import scala.collection.JavaConverters._

import org.apache.commons.io.IOUtils
import org.apache.http.client.methods.HttpGet
import org.apache.http.impl.client.CloseableHttpClient
import org.apache.http.impl.client.HttpClients


class TwitterStream(
  consumerKey: String,
  consumerSecret: String,
  accessToken: String,
  accessTokenSecret: String,
  path: String,
  savingInterval: Long,
  filters: Array[String]) {
  
  private val threadName = "tweet-downloader"
  
  {
    // Throw an exception if there is already an active stream.
    // We do this check at here to prevent users from overriding the existing
    // TwitterStream and losing the reference of the active stream.
    val hasActiveStream = Thread.getAllStackTraces().keySet().asScala.map(_.getName).contains(threadName)
    if (hasActiveStream) {
      throw new RuntimeException(
        "There is already an active stream that writes tweets to the configured path. " +
        "Please stop the existing stream first (using twitterStream.stop()).")
    }
  }
  
  @volatile private var thread: Thread = null
  @volatile private var isStopped = false
  @volatile var isDownloading = false
  @volatile var exception: Throwable = null

  private var httpclient: CloseableHttpClient = null
  private var input: InputStream = null
  private var httpGet: HttpGet = null
  
  private def encode(string: String): String = {
    URLEncoder.encode(string, StandardCharsets.UTF_8.name)
  }

  def start(): Unit = synchronized {
    isDownloading = false
    isStopped = false
    thread = new Thread(threadName) {
      override def run(): Unit = {
        httpclient = HttpClients.createDefault()
        try {
          requestStream(httpclient)
        } catch {
          case e: Throwable => exception = e
        } finally {
          TwitterStream.this.stop()
        }
      }
    }
    thread.start()
  }

  private def requestStream(httpclient: CloseableHttpClient): Unit = {
    val url = "https://stream.twitter.com/1.1/statuses/filter.json"
    val timestamp = System.currentTimeMillis / 1000
    val nonce = timestamp + scala.util.Random.nextInt
    val oauthNonce = nonce.toString
    val oauthTimestamp = timestamp.toString

    val oauthHeaderParams = List(
      "oauth_consumer_key" -> encode(consumerKey),
      "oauth_signature_method" -> encode("HMAC-SHA1"),
      "oauth_timestamp" -> encode(oauthTimestamp),
      "oauth_nonce" -> encode(oauthNonce),
      "oauth_token" -> encode(accessToken),
      "oauth_version" -> "1.0"
    )
    // Parameters used by requests
    // See https://dev.twitter.com/streaming/overview/request-parameters for a complete list of available parameters.
    val requestParams = List(
      "track" -> encode(filters.mkString(","))
    )

    val parameters = (oauthHeaderParams ++ requestParams).sortBy(_._1).map(pair => s"""${pair._1}=${pair._2}""").mkString("&")
    val base = s"GET&${encode(url)}&${encode(parameters)}"
    val oauthBaseString: String = base.toString
    val signature = generateSignature(oauthBaseString)
    val oauthFinalHeaderParams = oauthHeaderParams ::: List("oauth_signature" -> encode(signature))
    val authHeader = "OAuth " + ((oauthFinalHeaderParams.sortBy(_._1).map(pair => s"""${pair._1}="${pair._2}"""")).mkString(", "))

    httpGet = new HttpGet(s"https://stream.twitter.com/1.1/statuses/filter.json?${requestParams.map(pair => s"""${pair._1}=${pair._2}""").mkString("&")}")
    httpGet.addHeader("Authorization", authHeader)
    println("Downloading tweets!")
    val response = httpclient.execute(httpGet)
    val entity = response.getEntity()
    input = entity.getContent()
    if (response.getStatusLine.getStatusCode != 200) {
      throw new RuntimeException(IOUtils.toString(input, StandardCharsets.UTF_8))
    }
    isDownloading = true
    val reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8))
    var line: String = null
    var lineno = 1
    line = reader.readLine()
    var lastSavingTime = System.currentTimeMillis()
    val s = new StringBuilder()
    while (line != null && !isStopped) {
      lineno += 1
      line = reader.readLine()
      s.append(line + "\n")
      val now = System.currentTimeMillis()
      if (now - lastSavingTime >= savingInterval) {
        val file = new File(path, now.toString).getAbsolutePath
        println("saving to " + file)
        dbutils.fs.put(file, s.toString, true)
        lastSavingTime = now
        s.clear()
      }
    }
  }

  private def generateSignature(data: String): String = {
    val mac = Mac.getInstance("HmacSHA1")
    val oauthSignature = encode(consumerSecret) + "&" + encode(accessTokenSecret)
    val spec = new SecretKeySpec(oauthSignature.getBytes, "HmacSHA1")
    mac.init(spec)
    val byteHMAC = mac.doFinal(data.getBytes)
    return Base64.getEncoder.encodeToString(byteHMAC)
  }

  def stop(): Unit = synchronized {
    isStopped = true
    isDownloading = false
    try {
      if (httpGet != null) {
        httpGet.abort()
        httpGet = null
      }
      if (input != null) {
        input.close()
        input = null
      }
      if (httpclient != null) {
        httpclient.close()
        httpclient = null
      }
      if (thread != null) {
        thread.interrupt()
        thread = null
      }
    } catch {
      case _: Throwable =>
    }
  }
}


twitterStream.stop()

Thread.sleep(30000)

import sys.process._
"ls /dbfs/tmp/mounica"!! // tweets are written to these files. every 2 secs new file will be created

display(spark.read.text(path))

import java.sql.Timestamp

import org.apache.spark.sql.functions.{from_unixtime, unix_timestamp, window}
import org.apache.spark.sql.types.{StructType, StructField, StringType}

case class Twitter_data(start_time: Timestamp, text: String)

val clear = udf((s: String) => if (s == null) null else s.replaceAll("[^\\x20-\\x7e]", ""))
val data = spark.read.json(path)
display(data)

data
  .filter($"created_at".isNotNull)
  .withColumn("text", clear($"text"))
  .withColumn("created_at", from_unixtime(unix_timestamp($"created_at", "EEE MMM dd HH:mm:ss ZZZZ yyyy")))
  .select(
    window('created_at, "20 second").getField("start") as 'start_time,
    'text)
  .as[Twitter_data]   
 .filter(x => (x.text.toLowerCase.contains("dallas")&&x.text.toLowerCase.contains("restaurants")))
 .toDF("start_time", "tweet")
 .createOrReplaceTempView("tweets")


val df = sqlContext.sql("select * from tweets")
df.show()

import org.apache.spark._
import sqlContext.{sql, table}


val tweet_data = sqlContext.sql("""
  SELECT tweet, start_time
  FROM tweets
  ORDER BY start_time
""")
display(tweet_data) 


val count = sql("""
  SELECT count(*), start_time
  FROM tweets
  GROUP BY start_time
  ORDER BY start_time
""")
display(count)

import org.apache.spark.sql.functions._
import com.databricks.spark.corenlp.functions._

val data_input = data
  .filter($"created_at".isNotNull)
  .withColumn("text", clear($"text"))
  .withColumn("created_at", from_unixtime(unix_timestamp($"created_at", "EEE MMM dd HH:mm:ss ZZZZ yyyy")))
  .select(
    window('created_at, "10 second").getField("start") as 'start_time,
    'text)
  .as[Twitter_data]
 .filter(x => (x.text.toLowerCase.contains("dallas")&&x.text.toLowerCase.contains("restaurants")))
 .toDF("start_time", "tweet")


display(data_input)

val sentiment_data = data_input

  .select(explode(ssplit('tweet)).as('sen),'start_time).select('start_time, sentiment('sen).as('sentiment))

display(sentiment_data)

val final_output = sentiment_data.groupBy("start_time").avg("sentiment").orderBy("start_time")

display(final_output)
